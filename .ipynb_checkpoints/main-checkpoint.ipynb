{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKM/sem-Yawen Zhang\n",
    "\n",
    "## Step 1: get `data_dict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "file_path = \"iConference_edited/iConf2015.txt\"\n",
    "\n",
    "def parse_string(string):\n",
    "    string = \" \".join(string.split()) # remove duplicate spaces\n",
    "    no_whitespace = \"\".join(string.split())\n",
    "    index_right_a = no_whitespace.find(\">\") # find the index of right left angle braket\n",
    "    string_key = no_whitespace[1:index_right_a].lower()\n",
    "    string_value = string[index_right_a+2:]\n",
    "    return string_key, string_value\n",
    "\n",
    "# data format:\n",
    "# [\n",
    "# {\"author\": \"Mathiesen, Kay\",\n",
    "# \"title\": \"Indigenous Peoples' Rights to Culture and Individual Rights to Access\",\n",
    "# \"abstract\": \"xxx xxx xxx\", \n",
    "# \"ID\": \"iConf2015.txt-1\"},\n",
    "# {...}\n",
    "# ]\n",
    "def get_data_dict(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        file = list(f)\n",
    "    n = -1\n",
    "    data_dict = []\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line == \"\":\n",
    "            n += 1\n",
    "            data_dict.append({})\n",
    "            data_dict[n][\"ID\"] = \"%s-%s\" % (file_path, n)\n",
    "        else:\n",
    "            string_key, string_value = parse_string(line)\n",
    "            data_dict[n][string_key] = string_value\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: get `cleaned_data`\n",
    "\n",
    "There are some wrong data recordes in the 2015 file, for example:\n",
    "- `{'organization': 'North_America', 'type': 'Building upon efforts from other fields to conceptualize, we develop a typology of crowdsourcing for information science. Through a number of dimensions within the scope of motivation, centrality, beneficiary, aggregation, type of work, and type of crowd, our typology provides a way to understand crowdsourcing.\"', 'ID': 'iConference_edited/iConf2015.txt-20', 'title': 'Accepted', 'author': 'United States of America'}`\n",
    "\n",
    "To analyse data better, I keep the original `data_dict` but make other two dicts: `cleaned_data` and `wrong_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaned_and_wrong_data(data_dict):\n",
    "    cleaned_data = []\n",
    "    wrong_data = []\n",
    "    for item in data_dict:\n",
    "        if len(item['type'].split()) > 10 or item['title'] == \"Accepted\":\n",
    "            wrong_data.append(item)\n",
    "        else:\n",
    "            cleaned_data.append(item)\n",
    "    return cleaned_data, wrong_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'acceptance': 'Accepted', 'abstract': 'A new artisanship crop moored to information technology has emerged, and it is being heavily embraced in Nigeria. Guided by Maslow’s hierarchy of needs, this study examined job satisfaction among the information technology artisans in Nigeria. Job satisfaction was measured by whether the artisans wish to stay on the job, perceive their income as high or low, or consider the profession as having a good prospect; and on a binary scale of yes or no. The study also investigated how the socio-demographic characteristics of the respondents relate to their needs. Data was collected from 950 artisans randomly selected from two major locations in Nigeria with the aid of a questionnaire and an interview schedule. A breakdown of the Maslow’s variables predicted different job satisfaction differently just as the demographic and social characteristics of the respondents predicted the artisans’ needs differently.', 'topics': 'information technology and work', 'organization': 'University of South Africa, South Africa', 'region': 'Sub-Saharan_Africa', 'type': 'Completed Research Papers', 'country': 'South Africa', 'ID': 'iConference_edited/iConf2015.txt-0', 'keywords': 'information technology, artisans, Job satisfaction, Maslow, Nigeria', 'author': 'Nwagwu, Williams Ezinwa', 'title': 'Demographic and Maslow’s Motivation Predictors of Job Satisfaction of Information Technology Artisans in Nigeria'}, {'acceptance': 'Accepted', 'abstract': 'During the 2013 elections in Israel one of the major methods of interaction of the political parties and their leaders with potential voters was through their Facebook pages. These pages were followed for 50 days preceding the elections. For each page, 30% of the posts on the page were analyzed in terms of their rhetoric and subject. The largest number of the analyzed posts was intended for bonding with the audience, and unsurprisingly politics was the most frequent topic. The findings show that personal posts received the largest number of likes pointing to the personal nature of the elections. Findings were compared with results of analysis of the Facebook pages of the US Presidential candidates. Similarities were found, even though in Israel there is a party system and elections are not personal.', 'topics': 'communication studies, qualitative research methods, social media', 'organization': 'Bar-Ilan University, Israel', 'region': 'Middle_East', 'type': 'Completed Research Papers', 'country': 'Israel', 'ID': 'iConference_edited/iConf2015.txt-1', 'keywords': 'elections, social network sties, political fandom', 'author': 'Bar-Ilan, Judit; Bronstein, Jenny; Aharony, Noa', 'title': 'Israeli Parties and Party Leaders on Facebook during the 2013 Election Campaign'}]\n",
      "222\n"
     ]
    }
   ],
   "source": [
    "data_dict = get_data_dict(file_path)\n",
    "cleaned_data, wrong_data = cleaned_and_wrong_data(data_dict)\n",
    "\n",
    "print(cleaned_data[:2])\n",
    "print(len(cleaned_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'Building upon efforts from other fields to conceptualize, we develop a typology of crowdsourcing for information science. Through a number of dimensions within the scope of motivation, centrality, beneficiary, aggregation, type of work, and type of crowd, our typology provides a way to understand crowdsourcing.\"', 'title': 'Accepted', 'author': 'United States of America', 'organization': 'North_America', 'ID': 'iConference_edited/iConf2015.txt-20'}, {'type': 'This study adopts an interpretivist worldview within a critical paradigm to understand the world of Lanna culture and to explore storage, collection, access management, preservation and promotion of it in various libraries. The main approach is case studies underpinned by ethnography and field study.\"', 'title': 'Accepted', 'author': 'United Kingdom', 'organization': 'Western_Europe', 'ID': 'iConference_edited/iConf2015.txt-54'}]\n",
      "\n",
      "[ATTENTION!] There are at least 19 wrong data recodes needed to be checked manually.\n"
     ]
    }
   ],
   "source": [
    "print(wrong_data[:2])\n",
    "\n",
    "print(\"\\n[ATTENTION!] There are at least %s wrong data recodes needed to be checked manually.\" % len(wrong_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 3: Count `type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Posters': 91, 'Sessions for Interaction and Engagement': 11, 'Completed Research Papers': 49, 'Workshops': 32, 'Preliminary Results Papers': 39}\n"
     ]
    }
   ],
   "source": [
    "def get_specific_dict(data, key):\n",
    "    result = {}\n",
    "    for item in data:\n",
    "        if key in item:\n",
    "            value = item[key]\n",
    "            if value in result:\n",
    "                result[value] += 1\n",
    "            else:\n",
    "                result[value] = 1\n",
    "    return result\n",
    "\n",
    "print(get_specific_dict(cleaned_data, \"type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_dict = get_specific_dict(cleaned_data, \"type\")\n",
    "with open(\"type_all_frequency.csv\", \"w\") as f:\n",
    "    for item in type_dict:\n",
    "        f.write(\"%s,%s\\n\" % (item, type_dict[item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "http://stackoverflow.com/questions/34771191/matplotlib-taking-time-when-being-imported\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D = {u'Label1':26, u'Label2': 17, u'Label3':30}\n",
    "\n",
    "plt.bar(range(len(D)), D.values(), align='center')\n",
    "plt.xticks(range(len(D)), list(D.keys()))\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# D = {u'Label1':26, u'Label2': 17, u'Label3':30}\n",
    "\n",
    "# plt.bar(range(len(D)), D.values(), align='center')\n",
    "# plt.xticks(range(len(D)), list(D.keys()))\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# something's wrong with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# D = {u'Label1':26, u'Label2': 17, u'Label3':30}\n",
    "#\n",
    "# plt.bar(range(len(D)), D.values(), align='center')\n",
    "# plt.xticks(range(len(D)), list(D.keys()))\n",
    "#\n",
    "# plt.show()\n",
    "\n",
    "# print(mpl.get_cachedir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Count `region` & `country`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Asia': 9, 'Middle_East': 1, 'Western_Europe': 15, 'North_America': 176, 'Sub-Saharan_Africa': 1, 'South_America': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_specific_dict(cleaned_data, \"region\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save as csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region_dict = get_specific_dict(cleaned_data, \"region\")\n",
    "with open(\"region_all_frequency.csv\", \"w\") as f:\n",
    "    for item in region_dict:\n",
    "        f.write(\"%s,%s\\n\" % (item, region_dict[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'United Kingdom': 4, 'South Africa': 1, 'Germany': 4, 'Sweden': 2, 'Finland': 2, 'Denmark': 2, 'Chile': 1, \"China, People's Republic of\": 4, 'Korea, Republic of (South Korea)': 4, 'Canada': 15, 'Israel': 1, 'Japan': 1, 'United States of America': 161, 'Ireland': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_specific_dict(cleaned_data, \"country\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save as csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country_dict = get_specific_dict(cleaned_data, \"country\")\n",
    "with open(\"country_all_frequency.csv\", \"w\") as f:\n",
    "    for item in country_dict:\n",
    "        f.write(\"%s,%s\\n\" % (item, country_dict[item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Count `author`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gasson, Susan': 1, 'Chen, Feng': 1, 'Cottam, Joseph': 2, 'Gernandt, André (1)': 1, 'Zhao, Yuxiang': 1, 'Willis, Matt': 1, 'Shah, Chirag (2)': 1, 'Liu, Fang (1)': 1, 'Shin, Grace': 1, 'Morris, Rebecca Jane': 1, 'Wang, Jun': 1, 'Zavalina, Oksana L.': 1, 'Joshi, Ritu Virendra (2)': 1, 'Widdersheim, Michael Majewski': 1, 'Qin, Jian': 1, 'Costa, Mark': 1, 'Srinivasan, Janaki (1)': 1, 'Kusumakaulika, Nafiri': 1, 'Sabanovic, Selma (1)': 1, 'White, Kelvin': 1, 'Fu, Hengyi (1)': 1, 'Pan, Youneng (1,2)': 1, 'Hagen, Loni': 1, 'Sormunen, Eero (1)': 1, 'Zhu, Qinghua': 1, 'Honor, Leah': 1, 'Horseman, Rachel Lynn': 1, 'Edelblute, Trevor': 1, 'Brännback, Malin': 1, 'Morales, Miraida (1)': 1, 'Ennis-Cole, Demetria': 1, 'Kurup, Nikhil Gopinath': 1, 'Foster, Jonathan': 1, 'Lopatovska, Irene': 4, 'Bailey, Diane': 1, 'Gwizdka, Jacek': 2, 'Lipinsk, Mario (1)': 1, 'Shelton, Martin': 1, 'Ryu, Hohyon (4)': 1, 'Brooks, Catherine Francis': 1, 'Stock, Wolfgang G.': 1, 'Park, Hyoungjoo': 1, 'Yeh, Tom (1)': 1, 'Koizumi, Masanori': 1, 'Finn, Megan (2)': 1, 'Jones, Hilary (2)': 1, 'Baptista Nunes, Miguel (2)': 1, 'Newell, Bryce C': 1, 'Ramirez, Ivonne Saidé': 1, 'Raturi, Ankita': 2, 'Kharrazi, Hadi': 1, 'Lim, Sook': 1, 'Arvola, Paavo (1)': 1, 'Erickson, Ingrid': 6, 'Sugimoto, Cassidy R': 1, 'Richardson, Debra': 4, 'Marcinkowski, Michael': 1, 'Stiller, Juliane': 2, 'Oard, Douglas W. (5)': 1, 'Park, SoHyun': 1, 'Zhang, Yan (1)': 1, 'Xu, Xiaojuan': 1, 'Sula, Chris': 1, 'Castor, Maggie': 1, 'Inskip, Charles': 1, 'Järvelin, Anni (1)': 1, 'Nathan, Lisa': 4, 'Angeles, Jose': 1, 'Cheng, James (1)': 1, 'Gursoy, Ayse': 1, 'McClure, Charles R.': 1, 'Sawyer, Steven': 4, 'Welsh, Anne': 1, 'Caicedo Bastidas, Carlos Enrique': 1, 'Reynolds, Chloe': 1, 'Mostafa, Javed': 1, 'Poole, Erika Shehan': 1, 'Zhang, Guangxuan': 1, 'Shah, Chirag': 1, 'Demarest, Bradford': 1, 'Norton, Juliet': 2, 'Pine, Kathleen': 1, 'Organisciak, Peter': 1, 'Allard, Suzie (4)': 1, 'Alhoori, Hamed (1)': 1, 'Zhang, Yinglong': 1, 'Kettunen, Kimmo (2)': 1, 'Oh, Kyong Eun (1)': 1, 'Haimson, Oliver L.': 5, 'Nyström, Anna-Greta': 1, 'Cheng, An-Shou (3)': 1, 'Stromer-Galley, Jennifer': 1, 'Brooks, Brandon Allen (2)': 1, 'Baumer, Eric P. S. (2)': 1, 'Sonne, Jennifer': 1, 'Guo, Siyuan': 1, 'Takishima, Yasuhiro (1)': 1, 'Pellicone, Anthony James': 1, 'Bederson, Benjamin B.': 2, 'Eschler, Jordan': 4, 'Kammer, Jenna': 2, 'Maron, Deborah': 1, 'Xia, Huichuan (2)': 1, 'Wilkerson, Michelene': 1, 'Jarusawat, Piyapat': 1, 'Osterlund, Carsten': 1, 'Worrall, Adam': 1, 'Policicchio, Shauna Michelle (1)': 1, 'Downie, J. Stephen': 1, 'Thompson, Cheryl Annette (1)': 1, 'Harrison, Teresa M.': 1, 'Fallaw, Colleen': 1, 'Kitzie, Vanessa': 1, 'Kim, Jinyoung': 1, 'Allen, Warren': 4, 'Liu, Xiaozhong': 3, 'Carrington, Patrick (2)': 1, 'Aharony, Noa': 1, 'Battaglia, Eric': 1, 'Baker, Karen S. (1)': 1, 'Fidler, Bradley': 1, 'Peters, Elizabeth Hope': 1, 'Oh, Sam': 1, 'Sanders, Sean': 1, 'Tayag, Elnora': 1, 'Yu, Bei': 1, 'Cotten, Shelia': 1, 'Dombrowski, Lynn': 1, 'Shih, Patrick C.': 1, 'Joshi, KD (2)': 1, 'Fleischmann, Kenneth R. (1)': 1, 'Sharmin, Moushumi (2)': 1, 'Lee, Charlotte P.': 1, 'Ames, Morgan G. (3)': 1, 'Carlyle, Allyson': 1, 'Yan, Shiyan': 1, 'Ahn, June': 1, 'Ferro, Nicola (3)': 1, 'Broussard, Ramona': 1, 'Silberman, Six': 2, 'Lim, Hyunchul': 1, 'Sarcevic, Aleksandra': 1, 'Ko, Young Man': 1, 'Mattern, Eleanor': 1, 'Carrasquillo, Odemaris (2)': 1, 'Oh, Sanghee': 2, 'Slota, Steve (1)': 1, 'Shelia, Cotten (2)': 1, 'Oh, Chiyoung': 1, 'Guo, Chun': 2, 'Lesk, Michael (1)': 1, 'Howison, James': 1, 'Nahon, Karine (2,3)': 1, 'Lindström, Johanna': 1, 'Jett, Jacob': 1, 'Palmer, Carole L. (3)': 1, 'Hiles, Hannah Rose': 1, 'LaManna, Daniel': 1, 'Budd, John M.': 1, 'Goodale, Paula (1)': 2, 'Bronstein, Jenny': 1, 'Clement, Andrew': 2, 'Senseney, Megan': 1, 'Gruzd, Anatoliy': 2, 'Choi, Inkyung': 1, 'Herring, Susan C. (2)': 1, 'Morales, Myrna (2)': 1, 'Simons, Rachel': 1, 'Ji, Cheng (2)': 1, 'Fonseca, Frederico': 2, 'Terekhova, Vera (1)': 1, 'Larkin, Emily Elizabeth': 1, 'Diolola, Jan': 1, 'Haythornthwaite, Caroline': 2, 'Park, Hye-Jin': 1, 'Ramirez, Mario (3)': 1, 'Norton, Juliet (1)': 1, 'Kron, Tara': 1, 'Wulf, Volker (1)': 1, 'Olson, Gary M.': 1, 'Wohn, Donghee Yvette': 1, 'Carroll, John M.': 1, 'Kanan, Tarek (3)': 1, 'Carter, Daniel': 2, 'Choi, Wonchan': 1, 'Yavuz, Attila A. (2)': 1, 'Aviles, Frank Pancho': 1, 'Cai, Tingting (2)': 1, 'Gao, Huiqin': 1, 'Snyder, Jaime': 3, 'Silvello, Gianmaria (3)': 1, 'Shillair, R. J.': 1, 'Tomlinson, Bill': 4, 'Kluberdanz, Rebecca': 1, 'Davaloo, Milad': 1, 'Ekbia, Hamid R. (1)': 1, 'Choe, Sou Hwan': 1, 'James, David': 1, 'Jarrahi, Mohammad': 1, 'Shaffer, Elizabeth': 1, 'Hjalmarsson, Anders (1,2)': 1, 'Tomlinson, Bill (1)': 1, 'Zhou, Bin': 2, 'Alhabash, Saleem (1,2)': 1, 'Sawyer, Steve': 2, 'Peng, Alex': 1, 'Daly, Diane': 1, 'Todd, Ross': 4, 'Geiger, R. Staurt': 4, 'Penzenstadler, Birgit': 4, 'Tuomela, Mikko': 1, 'Lagoze, Carl': 1, 'Wang, Jun (1)': 1, 'Brannon, RaShauna (2)': 1, 'Stickel, Oliver (1)': 1, 'Järvelin, Kalervo (1)': 1, 'Maloney, Murray': 2, 'Ravi, S.S.': 1, 'Robert, LaRose (2)': 1, 'Zhang, Feifei': 1, 'Doty, Colin': 1, 'Sy, Erin': 1, 'Blevis, Eli': 2, 'Voida, Stephen': 4, 'Ocepek, Melissa': 1, 'Wada, Akiko': 1, 'Reay, Danielle (2)': 1, 'Barker, Lecia Jane': 1, 'Piell, Ron': 1, 'Rosenberg, Gary': 1, 'Champagne, Ryan': 1, 'Peekhaus, Wilhelm': 1, 'Dai, Bin': 1, 'Meschede, Christine': 1, \"O'Neill, Brittney\": 1, 'Chong, Steven': 1, 'Hemsley, Jeff': 2, 'Pelechrinis, Konstantinos': 1, 'Rifon, Nora J (1)': 1, 'Twidale, Michael': 1, 'Tan, Elliot (1)': 1, 'Comstock, Sharon': 1, 'Kazim, Nida': 1, 'Butts, Carter T. (2)': 1, 'Jeng, Wei': 1, 'Albertson, Dan': 2, 'Meuschke, Norman (1,2)': 2, 'Rosson, Mary Beth': 1, 'Lemieux, Vicki': 2, 'Xiao, Lu (1)': 2, 'Juncker, Beth': 4, 'Gomez, Ricardo': 1, 'Menking, Amanda': 4, 'Dumas, Catherine': 1, 'Kekäläinen, Jaana (1)': 1, 'Lin, Yuwei (2)': 1, 'Walker, Ashley Marie': 1, 'Khoo, Michael (1)': 1, 'Takayama, Yasuhiro (2)': 1, 'Pipek, Volkmar (1)': 1, 'Fisher, Karen': 4, 'Peled, Alon (1)': 1, 'Karlin, Beth': 2, 'Milowski, Alex': 2, 'Luong, Thuy T.B. (1)': 1, 'Gabb, Henry A.': 1, 'Lease, Matthew (2)': 1, 'Han, Kyungsik': 1, 'Furuta, Richard (1)': 1, 'Heckman, Judd Randolph': 1, 'Nakashole, Ndapandula': 1, 'Chizari, Sara': 1, 'Paine, Drew': 1, 'Choi, Heekyung': 2, 'Tomiura, Yoichi (4)': 1, 'Nguyen, Trung': 1, 'Waite, Peichi (2)': 1, 'Giles, C. Lee (2)': 1, 'Dedrick, Jason': 1, 'Massam, Diana (2)': 1, 'Lee, Florence': 1, 'Gustafsson, Eva (1)': 1, 'Todd, Ross J.': 1, 'Corso, Anthony Joseph': 1, 'Purao, Sandeep': 1, 'Currie, Morgan': 1, 'Shankar, Kalpana': 5, 'Tayag, Elnora (5)': 1, 'Huang, Kuo-Ting': 1, 'Kumpulainen, Sanna (1)': 1, 'Villa-Nicholas, Melissa': 1, 'Lo, Katherine': 1, 'Bar-Ilan, Judit': 1, 'Burton, Matt': 4, 'Nardi, Bonnie': 1, 'Tsaasan, Anita Marie': 1, 'Lucic, Ana': 1, 'Lee, Jongwook': 1, 'Widen, Gunilla': 1, 'Hartmann, Sarah': 1, 'Bogers, Toine': 1, 'Lee, Jisue': 1, 'Lu, Yihan': 1, 'LI, Xiaofeng': 1, 'Eikey, Elizabeth': 1, 'Reddy, Madhu': 1, 'Zaugg, Holt (1)': 1, 'Zheng, You': 1, 'Wen, Xidao': 1, 'Furlow, Tim': 1, 'Milojevic, Staša': 1, 'Bardoff, Corina': 1, 'Petras, Vivien (2)': 1, 'Kane, Shaun K. (1)': 1, 'Stanton, Jeff': 2, 'Barto, Thomas': 1, 'Kotfila, Christopher': 1, 'Tsai, Chun-Hua': 1, 'Ray Choudhury, Sagnik (2)': 1, 'Hattori, Gen (1)': 1, 'Koh, Kyungwon': 1, 'Bowler, Leanne': 1, 'Lee, Christopher (3)': 1, 'Wu, Shuheng (2)': 1, 'Rodriguez, Emely (1)': 1, 'Huang, Yun (2)': 1, 'Reed, Philip J. (1)': 1, 'Arapakis, Ioannis': 2, 'Srinivasan, Janaki (2)': 1, 'McNeirney, Katie': 1, 'Belkin, Nicholas (2)': 1, 'Sholler, Dan': 1, 'Crawford Barniskis, Shannon A': 1, 'Balling, Gitte': 4, 'Gray, LaVerne (4)': 1, 'Huvila, Isto': 1, 'Vakharia, Donna (1)': 1, 'Sharma, Sarika K': 1, 'Gruning, Jane': 1, 'Acker, Amelia': 4, 'Duerr, Ruth E. (2)': 1, 'Gray, LaVerne': 1, 'Raghavan, Barath (3)': 1, 'Vallejo, Jessica': 1, 'Xing, Wanli': 1, 'Wang, Yang': 2, 'Stahlman, Gretchen Renee': 1, 'Gäde, Maria': 2, 'Kizhakkethil, Priya': 1, 'Hu, Changping': 1, 'Teasley, Stephanie D.': 2, 'Arthur, Kathleen L. Arthur': 1, 'Poole, Erika': 1, 'Proferes, Nicholas John': 1, 'Dombrowski, Lynn Susan': 1, 'Mayernik, Matthew S. (2)': 1, 'Fisher, Brian': 2, 'Tenopir, Carol (4)': 1, 'Blake, Catherine': 2, 'Al johani, Arwa mohammed': 1, 'Fox, Edward (3)': 1, 'Glushko, Robert J.': 2, 'Martens, Marianne': 4, 'Ishizaki, Hiromi (1)': 1, 'Darch, Peter T.': 1, 'Nunes, Miguel': 1, 'Ahn, Jaewook (2)': 1, 'Su, Norman Makoto': 1, 'Oh, Jung Sun (3)': 1, 'Nathan, Lisa P.': 1, 'Trauth, Eileen (1)': 1, 'Du, Yunfei': 1, 'Bowker, Geoffrey C. (2)': 1, 'Grace, Rob': 1, 'Absar, Rafa': 2, 'Zhou, Lihong (1)': 1, 'Fleischmann, Kenneth': 4, 'Spiro, Emma S. (1)': 1, 'Lee, Jin Ha': 1, 'Lin, Yu-Ru': 3, 'Maden, Chris': 1, 'Boehmer, Erin Laurel': 1, 'Zhang, Zhan': 1, 'Saastamoinen, Miamaria (1)': 1, 'Goggins, Sean': 1, 'Xu, Yifei (2)': 1, 'Ribes, David': 4, 'Cheon, Eun Jeong': 1, 'Askin, Nicole (2)': 1, 'Massimi, Michael (2)': 1, 'Pufal, Marcel (1)': 1, 'Ishita, Emi (4)': 1, 'Gilbert, Sarah': 2, 'Sabaghian, Ehsan': 1, 'Centivany, Alissa Lorraine': 3, 'Meyers, Eric': 4, 'Farzan, Rosta': 2, 'Chen, Jiangping': 1, 'Clarke, Rachel Ivy': 1, 'Burnett, Gary': 1, 'DesArmo, Joel': 1, 'Lease, Matthew (1)': 1, 'Boden, Alexander (2)': 1, 'Huang, Ru Hua (1)': 1, 'Buchanan, Sarah': 1, 'Karami, Amir': 2, 'Alemanne, Nicole D.': 1, 'Tsou, Andrew': 1, 'Kropczynski, Jess': 1, 'Sanfilippo, Madelyn Rose': 1, 'Missen, Cliff': 1, 'Hosmer, Shannon (2)': 1, 'Nwagwu, Williams Ezinwa': 1, 'Houston, Douglas (2)': 1, 'Tsaasan, Anita Marie (1)': 1, 'Heidorn, P. Bryan': 1, 'Pascal, Connie': 1, 'Langmead, Alison': 1, 'Mainka, Agnes': 1, 'Jiang, Mengtian (1)': 1, 'Manoharan, Monisha (2)': 1, 'Jiang, Tingting': 1, 'Wang, Xin (2)': 1, 'Ermolaev, Natalia (2)': 1, 'Rosenbaum, Howard': 1, 'Steffel, Nick': 1, 'Stratton, Caroline': 2, 'Small, Heather': 1, 'Fichman, Pnina': 1, 'Oreglia, Elisa (1)': 1, 'Xu, Qiong': 1, 'Cotten, S.R.': 1, 'Spears, Laura I.': 2, 'Lu, Di': 2, 'Mott, Martez': 1, 'zhang, xiangmin': 1, 'Lonn, Steven': 1, 'Keskustalo, Heikki (1)': 1, 'Ball, Christopher': 1, 'Li, Wenqi (1)': 1, 'Sands, Ashley E.': 1, 'Rikard, R.V.': 1, 'Lee, Jisue (1)': 1, 'Cheng, Karen G. (1)': 1, 'Nardi, Bonnie (2)': 1, 'Campbell, Sheena': 1, 'Eastmure, Vanessa (1)': 1, 'De Choudhury, Munmun (1)': 1, 'Rabina, Debbie Lee': 1, 'Lin, YuWei (2)': 1, 'Depew, Michael': 1, 'Jang, Wonhong': 1, 'Ahmed, Shameem (1)': 1, 'Zhang, Jingwen': 1, 'Kvasny, Lynette (1)': 1, 'Rubenstein, Ellen': 1, 'Mazmanian, Melissa': 1, 'Dessne, Karin': 1, 'Gangopadhyay, Aryya': 1, 'Johnston, Melissa': 1, 'Tsai, H.Y.': 1, 'Khoo, Michael': 1, 'Bates, Jo (1)': 2, 'Lee, Jon (3)': 1, 'Tarullo, Leigh A. Tarullo': 1, 'Gonzalez-Ibañez, Roberto I (1)': 1, 'Fleischmann, Kenneth R.': 2, 'Quigley, Aisling': 1, 'Hurst, Amy (2)': 1, 'Espinoza Vasquez, Fatima Karely': 1, 'Zhou, Angela (4)': 1, 'Becker, Christoph': 2, 'Paulin, Drew': 2, 'Han, Sangeun': 1, 'Moon, Eunyoung': 1, 'Park, Min Sook': 2, 'Lee, Shaoshing': 1, 'Guzman, Indira': 1, 'Leon, Claudio A. Leon': 1, 'Smith, Daniella': 1, 'Shilton, Katie': 3, 'Cronholm, Stefan (1)': 1, 'Cocciolo, Anthony': 1, 'Simons, Rachel Noelle': 1, 'Stvilia, Besiki': 1, 'Petras, Vivien': 2, 'Rennick, Brian (1)': 1, 'Zimmer, Michael': 1, 'Hayes, Gillian R.': 5, 'Shaw, Jodi': 1, 'Brubaker, Jed R.': 2, 'Isaac, Antoine': 2, 'Ly, Rebecca': 1, 'Lee, Myeong': 1, 'Purcell, Michelle': 1, 'Gipp, Bela (1)': 2, 'Kilgour, Lauren': 1, 'Baeg, Jung Hoon': 1, 'Wang, Dakuo': 1, 'Dang, Tuan Cong': 1, 'Loder, Courtney': 2, 'Liu, Xiaozhong (2)': 1, 'Mardis, Marcia A.': 1, 'Olson, Judith S.': 1, 'Ambaparavu, Chandrahasa': 1, 'Bogers, Toine (1)': 1, 'Mortensen, Eric': 1, \"O'Brien, Heather L.\": 3, 'Chen, Miao': 1, 'Ludwig, Thomas (1)': 1}\n"
     ]
    }
   ],
   "source": [
    "def get_author_dict(data):\n",
    "    result = {}\n",
    "    for item in data:\n",
    "        string = item[\"author\"]\n",
    "        list_author = string.split(\"; \")\n",
    "        for item in list_author:\n",
    "            if item in result:\n",
    "                result[item] += 1\n",
    "            else:\n",
    "                result[item] = 1\n",
    "    return result\n",
    "\n",
    "print(get_author_dict(cleaned_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lopatovska, Irene : 4\n",
      "Erickson, Ingrid : 6\n",
      "Richardson, Debra : 4\n",
      "Nathan, Lisa : 4\n",
      "Sawyer, Steven : 4\n",
      "Haimson, Oliver L. : 5\n",
      "Eschler, Jordan : 4\n",
      "Allen, Warren : 4\n",
      "Liu, Xiaozhong : 3\n",
      "Snyder, Jaime : 3\n",
      "Tomlinson, Bill : 4\n",
      "Todd, Ross : 4\n",
      "Geiger, R. Staurt : 4\n",
      "Penzenstadler, Birgit : 4\n",
      "Voida, Stephen : 4\n",
      "Juncker, Beth : 4\n",
      "Menking, Amanda : 4\n",
      "Fisher, Karen : 4\n",
      "Shankar, Kalpana : 5\n",
      "Burton, Matt : 4\n",
      "Balling, Gitte : 4\n",
      "Acker, Amelia : 4\n",
      "Martens, Marianne : 4\n",
      "Fleischmann, Kenneth : 4\n",
      "Lin, Yu-Ru : 3\n",
      "Ribes, David : 4\n",
      "Centivany, Alissa Lorraine : 3\n",
      "Meyers, Eric : 4\n",
      "Shilton, Katie : 3\n",
      "Hayes, Gillian R. : 5\n",
      "O'Brien, Heather L. : 3\n"
     ]
    }
   ],
   "source": [
    "author_dict = get_author_dict(cleaned_data)\n",
    "\n",
    "for item in author_dict:\n",
    "    if author_dict[item] >= 3:\n",
    "        print(\"%s : %s\" % (item, author_dict[item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save as csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"author_all_frequency.csv\", \"w\") as f:\n",
    "    for item in author_dict:\n",
    "        f.write(\"%s,%s\\n\" % (item, author_dict[item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Count `keywords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information policy : 6\n",
      "gender : 5\n",
      "ethics : 3\n",
      "collaboration : 4\n",
      "research agenda : 4\n",
      "crowdsourcing : 5\n",
      "Sociotechnical : 4\n",
      "online communities : 4\n",
      "values in design : 4\n",
      "sexuality : 4\n",
      "design : 8\n",
      "information ethics : 3\n",
      "Social Media : 4\n",
      "digital youth : 5\n",
      "metadata : 3\n",
      "social network analysis : 4\n",
      "research methods : 4\n",
      "trace data : 4\n",
      "education : 6\n",
      "CSST : 4\n",
      "data analysis : 4\n",
      "sustainability : 7\n",
      "social media : 7\n",
      "trace ethnography : 4\n",
      "Facebook : 4\n",
      "privacy : 4\n",
      "learning : 4\n",
      "Twitter : 5\n",
      "race : 4\n"
     ]
    }
   ],
   "source": [
    "def get_keyword_dict(data):\n",
    "    result = {}\n",
    "    for item in data:\n",
    "        if \"keywords\" in item:\n",
    "            string = item[\"keywords\"]\n",
    "            list_keyword = string.split(\", \")\n",
    "            for item in list_keyword:\n",
    "                if item in result:\n",
    "                    result[item] += 1\n",
    "                else:\n",
    "                    result[item] = 1\n",
    "    return result\n",
    "\n",
    "keyword_dict = get_keyword_dict(cleaned_data)\n",
    "\n",
    "for item in keyword_dict:\n",
    "    if keyword_dict[item] >= 3:\n",
    "        print(\"%s : %s\" % (item, keyword_dict[item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save as csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"keywords_all_frequency.csv\", \"w\") as f:\n",
    "    for item in keyword_dict:\n",
    "        f.write(\"%s,%s\\n\" % (item, keyword_dict[item]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Count `abstract`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new', 'artisanship', 'crop', 'moored', 'information', 'technology', 'emerged', 'heavily', 'embraced', 'nigeria', 'guided', 'maslow’s', 'hierarchy', 'needs', 'study', 'examined', 'job', 'satisfaction', 'among', 'information', 'technology', 'artisans', 'nigeria', 'job', 'satisfaction', 'measured', 'whether', 'artisans', 'wish', 'stay', 'job', 'perceive', 'income', 'high', 'low', 'consider', 'profession', 'good', 'prospect', 'binary', 'scale', 'yes', 'study', 'also', 'investigated', 'socio-demographic', 'characteristics', 'respondents', 'relate', 'needs', 'data', 'collected', '950', 'artisans', 'randomly', 'selected', 'two', 'major', 'locations', 'nigeria', 'aid', 'questionnaire', 'interview', 'schedule', 'breakdown', 'maslow’s', 'variables', 'predicted', 'different', 'job', 'satisfaction', 'differently', 'demographic', 'social', 'characteristics', 'respondents', 'predicted', 'artisans’', 'needs', 'differently', '2013', 'elections', 'israel', 'one', 'major', 'methods', 'interaction', 'political', 'parties', 'leaders', 'potential', 'voters', 'facebook', 'pages', 'pages', 'followed', '50', 'days', 'preceding', 'elections', 'page', '30', 'posts', 'page', 'analyzed', 'terms', 'rhetoric', 'subject', 'largest', 'number', 'analyzed', 'posts', 'intended', 'bonding', 'audience', 'unsurprisingly', 'politics', 'frequent', 'topic', 'findings', 'show', 'personal', 'posts', 'received', 'largest', 'number', 'likes', 'pointing', 'personal', 'nature', 'elections', 'findings', 'compared', 'results', 'analysis', 'facebook', 'pages', 'us', 'presidential', 'candidates', 'similarities', 'found', 'even', 'though', 'israel', 'party', 'system', 'elections', 'personal', 'anticipatory', 'technology', 'ethics', 'practice', 'analyzing', 'emerging', 'technologies', 'built', 'imagining', 'might', 'used', 'interpreting', 'consequences', 'might', 'information', 'researchers', 'professionals', 'increasingly', 'interested', 'understanding', 'possible', 'social', 'impacts', 'technologies', 'wide-spread', 'deployment', 'anticipatory', 'technology', 'ethics', 'provides', 'one', 'lens', 'paper', 'reports', 'two', 'anticipatory', 'ethics', 'projects', 'contrasting', 'projects', 'tested', 'techniques', 'practicing', 'anticipatory', 'ethics', 'also', 'illuminated', 'challenges', 'stem', 'diverse', 'engineering', 'work', 'practices', 'design', 'user-facing', 'versus', 'infrastructural', 'technologies', 'particular', 'paper', 'focuses', 'problem', 'layer', 'ethical', 'issues', 'found', 'technology', 'design', 'ways', 'material', 'realities', 'design', 'impact', 'developers’', 'willingness', 'readiness', 'participate', 'anticipatory', 'ethics', 'popularity', 'social', 'tagging', 'sparked', 'great', 'deal', 'debate', 'whether', 'tags', 'could', 'replace', 'improve', 'upon', 'professional', 'metadata', 'descriptors', 'books', 'information', 'objects', 'paper', 'present', 'large-scale', 'empirical', 'comparison', 'contributions', 'individual', 'information', 'elements', 'like', 'core', 'bibliographic', 'data', 'controlled', 'vocabulary', 'terms', 'reviews', 'tags', 'retrieval', 'performance', 'comparison', 'done', 'using', 'test', 'collection', 'million', 'book', 'records', 'information', 'elements', 'amazon', 'british', 'library', 'library', 'congress', 'librarything', 'find', 'tags', 'controlled', 'vocabulary', 'terms', 'actually', 'outperform', 'consistently', 'seem', 'provide', 'complementary', 'contributions', 'information', 'needs', 'best', 'addressed', 'using', 'controlled', 'vocabulary', 'terms', 'whereas', 'best', 'addressed', 'using', 'tags', 'digital', 'fabrication', 'technologies', 'great', 'potential', 'empowering', 'consumers', 'produce', 'creations', 'however', 'despite', 'growing', 'availability', 'digital', 'fabrication', 'technologies', 'shared', 'machine', 'shops', 'fablabs', 'university', 'labs', 'often', 'perceived', 'difficult', 'use', 'especially', 'users', 'limited', 'technological', 'aptitude', 'hence', 'yet', 'clear', 'potentials', 'technology', 'made', 'accessible', 'broader', 'public', 'remain', 'limited', 'form', '“maker', 'elite”', 'paper', 'study', 'appropriation', 'digital', 'fabrication', 'example', 'use', '3d', 'printers', 'two', 'different', 'communities', 'analyze', 'users', 'conceptualize', 'use', '3d', 'printers', 'kind', 'contextual', 'understanding', 'necessary', 'work', 'machines', 'users', 'document', 'share', 'knowledge', 'based', 'empirical', 'findings', 'identify', 'potentials', 'machines', 'offer', 'communities', 'kind', 'challenges', 'overcome', 'appropriation', 'technology']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_abstract_tokens(data):\n",
    "    tokens = []\n",
    "    stopwords=[word.strip().lower() for word in open(\"english_stopwords.txt\")]\n",
    "    for item in data:\n",
    "        if \"abstract\" in item:\n",
    "            list_token = word_tokenize(item[\"abstract\"])\n",
    "            for item in list_token:\n",
    "                item = item.strip().lower()\n",
    "                if item not in stopwords and len(item) > 1:\n",
    "                    tokens.append(item)\n",
    "    return tokens\n",
    "\n",
    "test = (cleaned_data)[:5]\n",
    "a = get_abstract_tokens(test)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('information', 232), ('data', 229), ('research', 139), ('study', 135), ('social', 124), ('use', 86), ('users', 79), ('analysis', 77), ('design', 77), ('paper', 72), ('using', 70), ('work', 66), ('workshop', 63), ('digital', 62), ('community', 62), ('also', 59), ('results', 58), ('media', 56), ('user', 56), ('participants', 56), ('different', 52), ('systems', 51), ('online', 50), ('new', 47), ('findings', 45), ('two', 45), ('researchers', 45), ('public', 44), ('within', 44), ('students', 43), ('knowledge', 42), ('learning', 41), ('behavior', 40), ('library', 40), ('used', 40), ('based', 39), ('development', 38), ('understanding', 37), ('support', 37), ('questions', 36), ('may', 36), ('methods', 35), ('identify', 35), ('process', 35), ('many', 35), ('science', 34), ('challenges', 34), ('present', 34), ('search', 34), ('practices', 34), ('system', 33), ('technology', 32), ('experience', 32), ('trace', 32), ('web', 32), ('one', 31), ('implications', 31), ('approach', 31), ('network', 30), ('provides', 30), ('studies', 30), ('project', 30), ('resources', 29), ('model', 29), ('collection', 29), ('communities', 29), ('access', 28), ('however', 28), ('provide', 28), ('twitter', 28), ('conducted', 28), ('explore', 28), ('scholars', 27), ('future', 27), ('discuss', 27), ('ischools', 27), ('types', 26), ('needs', 26), ('academic', 26), ('field', 25), ('metadata', 25), ('understand', 25), ('poster', 25), ('qualitative', 24), ('``', 24), ('cultural', 23), ('communication', 23), ('various', 23), ('current', 23), ('management', 23), ('sustainability', 23), ('open', 23), ('tools', 23), ('life', 23), ('documents', 23), ('interviews', 22), ('session', 22), ('opportunities', 22), ('important', 22), ('conference', 22), ('features', 22), ('found', 22), ('content', 22), ('review', 22), ('need', 22), ('ict', 21), ('practice', 21), ('around', 21), ('factors', 21), ('among', 21), ('well', 21), ('groups', 21), ('scientific', 21), ('ischool', 21), ('education', 20), ('people', 20), ('topic', 20), ('presents', 20), ('survey', 20), ('time', 20), ('discussion', 20), ('services', 20), ('existing', 20), ('sites', 19), ('context', 19), ('technologies', 19), ('approaches', 19), ('preliminary', 19), ('including', 19), ('interaction', 19), ('related', 19), ('help', 19), ('ethnography', 19), ('patterns', 19), ('several', 19), ('often', 19), ('interactive', 19), ('libraries', 18), ('collected', 18), ('make', 18), ('set', 18), ('activities', 18), ('gender', 17), ('literature', 17), ('devices', 17), ('major', 17), ('retrieval', 17), ('foster', 17), ('contexts', 17), ('large', 17)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "tokens = get_abstract_tokens(cleaned_data)\n",
    "Freq_dist_nltk=nltk.FreqDist(tokens)\n",
    "print(Freq_dist_nltk.most_common(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "f150 = Freq_dist_nltk.most_common(150)\n",
    "print(type(f150[0]))\n",
    "# for item in f150:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save as csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1688"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"abstract_token_most_common_150.csv\", \"w\").write('\\n'.join('%s,%s' % x for x in f150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
